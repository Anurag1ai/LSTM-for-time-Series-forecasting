{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\AnuragDubey\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:458: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\AnuragDubey\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:459: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\AnuragDubey\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:460: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\AnuragDubey\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:461: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\AnuragDubey\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:462: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\AnuragDubey\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:465: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import datetime\n",
    "import warnings \n",
    "warnings.\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.api import adfuller\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dateparser(X):\n",
    "    return datetime.strptime(\"190\"+X,\"%Y-%m\")\n",
    "\n",
    "#convert time series into supervised learning problem\n",
    "def series_to_supervised(data,n_In,n_Out, dropnan= True):\n",
    "    n_vars =1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(),list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_In,0,-1):\n",
    "        cols.append(df.shift(i))\n",
    "        names+=[\"var%d(t-%d)\"% (j+1,i) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0,n_Out):\n",
    "        cols.append(df.shift(-i))\n",
    "        names+=[\"var%d(t+%d)\"%(j+1,i) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols,axis=1)\n",
    "    agg.columns= names\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace= True)\n",
    "    return agg\n",
    "#preparing train test data\n",
    "def prepareData(series,n_test,n_lag,n_seq):\n",
    "    rawData = series.values\n",
    "    rawData =rawData.reshape(len(rawData),1)\n",
    "    supervised = series_to_supervised(rawData,n_lag,n_seq)\n",
    "    supervisedVal = supervised.values\n",
    "    train,test = supervisedVal[0:-n_test],supervisedVal[-n_test:]\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (23, 4), test (10, 4)\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "data= pd.read_csv(\"C:\\\\TensorFlow\\\\LSTM\\\\shamData.csv\",index_col=0, parse_dates=[0],date_parser= dateparser)\n",
    "train,test = prepareData(data,10,1,3)\n",
    "print(\"Train %s, test %s\"% (str(train.shape),str(test.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[342.3, 339.7, 440.4, 315.9],\n",
       "       [339.7, 440.4, 315.9, 439.3],\n",
       "       [440.4, 315.9, 439.3, 401.3],\n",
       "       [315.9, 439.3, 401.3, 437.4],\n",
       "       [439.3, 401.3, 437.4, 575.5],\n",
       "       [401.3, 437.4, 575.5, 407.6],\n",
       "       [437.4, 575.5, 407.6, 682. ],\n",
       "       [575.5, 407.6, 682. , 475.3],\n",
       "       [407.6, 682. , 475.3, 581.3],\n",
       "       [682. , 475.3, 581.3, 646.9]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def persistence(last_ob, n_seq):\n",
    "    return [last_ob for i in range(n_seq)]\n",
    "def make_forecasts(train, test, n_lag, n_seq):\n",
    "    forecasts = list()\n",
    "    for i in range(len(test)):\n",
    "        X, y = test[i, 0:n_lag], test[i, n_lag:]\n",
    "    # make forecast\n",
    "        forecast = persistence(X[-1], n_seq)\n",
    "        # store the forecast\n",
    "        forecasts.append(forecast)\n",
    "    return forecasts\n",
    "\n",
    "forecasts = make_forecasts(train, test, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t+1 RMSE: 144.535304\n",
      "t+2 RMSE: 86.479905\n",
      "t+3 RMSE: 121.149168\n"
     ]
    }
   ],
   "source": [
    "def evaluate_forecasts(test, forecasts, n_lag, n_seq):\n",
    "    for i in range(n_seq):\n",
    "        actual = test[:,(n_lag+i)]\n",
    "        predicted = [forecast[i] for forecast in forecasts]\n",
    "        rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
    "        print('t+%d RMSE: %f' % ((i+1), rmse))\n",
    "evaluate_forecasts(test,forecasts,1,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Multi-Step LSTM Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stationary. The data shows an increasing trend that must be removed by differencing.\n",
    "Scale. The scale of the data must be reduced to values between -1 and 1, the activation function of the LSTM units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def series_to_supervised(data,n_In,n_Out, dropnan= True):\n",
    "    n_vars =1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(),list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_In,0,-1):\n",
    "        cols.append(df.shift(i))\n",
    "        names+=[\"var%d(t-%d)\"% (j+1,i) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0,n_Out):\n",
    "        cols.append(df.shift(-i))\n",
    "        names+=[\"var%d(t+%d)\"%(j+1,i) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols,axis=1)\n",
    "    agg.columns= names\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace= True)\n",
    "    return agg\n",
    "\n",
    "def difference(data,interval=1):\n",
    "    diff= list()\n",
    "    for i in range(interval,len(data)):\n",
    "        val = data[i]-data[i-interval]\n",
    "        diff.append(val)\n",
    "    return pd.Series(diff)\n",
    "\n",
    "def prepareData(data,n_test,n_leg,n_seq):\n",
    "    rawVal = data.values\n",
    "    diffSeries = difference(rawVal,1)\n",
    "    diffVals = diffSeries.values\n",
    "    diffVals =diffVals.reshape(len(diffVals),1)\n",
    "    scaler= MinMaxScaler()\n",
    "    scaler = scaler.fit(diffVals)\n",
    "    scaledVal = scaler.fit_transform(diffVals)\n",
    "    scaledVal = scaledVal.reshape(len(scaledVal),1)\n",
    "    supervised = series_to_supervised(scaledVal, n_leg, n_seq)\n",
    "    supervised_values = supervised.values\n",
    "    # split into train and test sets\n",
    "    train, test = supervised_values[0:-n_test], supervised_values[-n_test:]\n",
    "    return scaler, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_lstm(train, n_lag, n_seq, n_batch, nb_epoch, n_neurons):\n",
    "    # reshape training into [samples, timesteps, features]\n",
    "    X,y = train[:,0:n_lag],train[:,n_lag:]\n",
    "    X= X.reshape(X.shape[0],1,X.shape[1])\n",
    "    #design network\n",
    "    model= Sequential()\n",
    "    model.add(LSTM(n_neurons,batch_input_shape=(n_batch,X.shape[1],X.shape[2]),stateful=True,return_sequences=True))\n",
    "    model.add(LSTM(2,stateful=True))\n",
    "    model.add(Dense(y.shape[1]))\n",
    "    model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "    # fit the network\n",
    "    for i in range(nb_epoch):\n",
    "        model.fit(X,y,epochs=1,batch_size=n_batch,verbose=0,shuffle= False)\n",
    "        model.reset_states()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single forecast can be made with the fit LSTM network by calling model.predict(). Again, the data must be formatted into a 3D array with the format [samples, timesteps, features]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forcast_lstm(model, X, n_batch):\n",
    "    X= X.reshape(1,1,len(X))\n",
    "    #make forecast\n",
    "    forecast = model.predict(X,batch_size=n_batch)\n",
    "    #convert to array\n",
    "    return([x for x in forecast[0,:]])\n",
    "# evaluate the persistence model\n",
    "def make_forecast(model,n_batch,train,test,n_lag,n_seq):\n",
    "    forecasts = list()\n",
    "    for i in range(len(test)):\n",
    "        X,y = test[i,0:n_lag],test[i,n_lag:]\n",
    "        forecast = forcast_lstm(model,X,n_batch)\n",
    "        forecasts.append(forecast)\n",
    "    return forecasts\n",
    "#make forecast\n",
    "forecasts = make_forecast(model,1,train,test,1,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invert Transforms\n",
    "\n",
    "\n",
    "After the forecasts have been made, we need to invert the transforms to return the values back into the original scale.\n",
    "This is needed so that we can calculate error scores and plots that are comparable with other models, like the persistence forecast above.\n",
    "We can invert the scale of the forecasts directly using the MinMaxScaler object that offers an inverse_transform() function.\n",
    "\n",
    "We can invert the differencing by adding the value of the last observation (prior months’ shampoo sales) to the first forecasted value, then propagating the value down the forecast.\n",
    "This is a little fiddly; we can wrap up the behavior in a function name inverse_difference() that takes the last observed value prior to the forecast and the forecast as arguments and returns the inverted forecast.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inverse_difference(last_obser,forecast):\n",
    "    #invert first forecast\n",
    "    inverted= list()\n",
    "    inverted.append(forecast[0]+last_obser)\n",
    "    #propogate difference forecast using inverted value\n",
    "    for i in range(1,len(forecast)):\n",
    "        inverted.append(forecast[i]+inverted[i-1])\n",
    "    return inverted\n",
    "#Putting this together, we can create an inverse_transform() function that works through each forecast,\n",
    "#first inverting the scale and then inverting the differences, returning forecasts to their original scale.\n",
    "def inverse_transform(series,forecasts,scaler,n_test):\n",
    "    inverted = list()\n",
    "    for i in range(len(forecasts)):\n",
    "        #create an array for forecast\n",
    "        forecast = np.array(forecasts[i])\n",
    "        forecast= forecast.reshape(1,len(forecast))\n",
    "        #invert scaling\n",
    "        inv_scale = scaler.inverse_transform(forecast)\n",
    "        inv_scale = inv_scale[0,:]\n",
    "        #invert differencing\n",
    "        index = len(series)-n_test+i-1\n",
    "        last_obser = series.values[index]\n",
    "        inv_diff= inverse_difference(last_obser,inv_scale)\n",
    "        inverted.append(inv_diff)\n",
    "    return inverted\n",
    "\n",
    "# evaluate the RMSE for each forecast time step\n",
    "def evaluate_forecasts(test, forecasts, n_lag, n_seq):\n",
    "    for i in range(n_seq):\n",
    "        actual = [row[i] for row in test]\n",
    "        predicted = [forecast[i] for forecast in forecasts]\n",
    "        rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
    "        print('t+%d RMSE: %f' % ((i+1), rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AnuragDubey\\Anaconda3\\envs\\tfdeeplearning\\lib\\site-packages\\sklearn\\utils\\validation.py:444: DataConversionWarning: Data with input dtype object was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "series = pd.read_csv(\"C:\\\\TensorFlow\\\\LSTM\\\\shamData.csv\",index_col=0, parse_dates=[0],date_parser= dateparser)\n",
    "# configure\n",
    "n_lag=1\n",
    "n_seq =3\n",
    "n_test=10\n",
    "n_epochs=600\n",
    "n_batch=1\n",
    "n_neurons=2\n",
    "\n",
    "# prepare data\n",
    "scaler, train, test = prepareData(series, n_test, n_lag, n_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit model\n",
    "model = fit_lstm(train, n_lag, n_seq, n_batch, n_epochs, n_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make forecasts\n",
    "forecasts = make_forecast(model, n_batch, train, test, n_lag, n_seq)\n",
    "# inverse transform forecasts and test\n",
    "forecasts = inverse_transform(series, forecasts, scaler, n_test+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t+1 RMSE: 144.064122\n",
      "t+2 RMSE: 84.701543\n",
      "t+3 RMSE: 109.072262\n"
     ]
    }
   ],
   "source": [
    "actual = [row[n_lag:] for row in test]\n",
    "actual = inverse_transform(series, actual, scaler, n_test+2)\n",
    "# evaluate forecasts\n",
    "evaluate_forecasts(actual, forecasts, n_lag, n_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
